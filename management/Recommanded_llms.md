Recommended Open-Source LLMs for CamusThis list provides a starting point for selecting a local LLM to power the Camus CLI. The best choice depends on the user's hardware (RAM/VRAM) and the complexity of the coding tasks. All models listed are available in the llama.cpp-compatible GGUF format on platforms like Hugging Face.ModelSize (Parameters)StrengthsWeaknessesIdeal Use Case in CamusLlama 3 8B Instruct8BState-of-the-art reasoning for its size. Excellent instruction follower. Very fast on most systems.Can lack the deeper context of larger models for whole-repository questions.Default choice. Perfect for modify, commit, and fixing build/test errors on typical consumer hardware.Mistral 7B Instruct7BLegendary performance-to-size ratio. Extremely fast and resource-light.Less proficient than newer models like Llama 3 at complex, multi-step tasks.Quick, simple tasks: generating boilerplate, fixing syntax errors, fast commit messages.Mixtral 8x7B Instruct~47B (MoE)Near 70B-level performance with much lower RAM usage and faster inference than dense models.Can be resource-intensive (~24GB VRAM recommended for good performance).High-quality refactor and complex modify tasks on high-end consumer hardware.DeepSeek Coder 6.7B6.7BHighly specialized for code generation and understanding. Often outperforms generalist models of the same size on code tasks.May be less "creative" or proficient at general language tasks (e.g., nuanced documentation).Excellent for the core modify and refactor commands where code correctness is paramount.DeepSeek Coder 33B33BA top-tier coding model. Balances extreme coding proficiency with manageable (though high) resource needs.Requires significant VRAM/RAM. Overkill for simple tasks.Complex, project-wide refactoring or modifications involving multiple files.Llama 3 70B Instruct70BOne of the most powerful open-source models available. Can understand vast, complex codebases and instructions.Extremely high resource requirements. Slower inference speeds.Mission-critical, complex architectural refactor or modify commands where quality is non-negotiable.Code Llama 13B13BA solid, code-specialized model that provides a step-up from 7B models without huge resource jumps.Based on older Llama 2 architecture; newer models are often more capable.A good mid-range option for all core commands (modify, refactor, build fix).Phind-CodeLlama-34B34BFine-tuned specifically on high-quality programming problems and solutions. Excellent at logical problem-solving.Can be less of a general instruction-follower than other instruct models.Perfect for debugging. Analyzing build and test failures to find the root cause.WizardCoder 33B33BFine-tuned to follow very complex and nuanced instructions.Can sometimes "overthink" simple problems.The refactor command, especially with complex requirements like "change this class to use the pimpl idiom."Phi-3 Mini 3.8B3.8BIncredibly powerful for its tiny size. Runs on almost any hardware and is exceptionally fast.Lacks the deep reasoning for complex tasks. May hallucinate more on difficult problems.Lightning-fast syntax correction, boilerplate, and simple modify requests on very low-power devices.
