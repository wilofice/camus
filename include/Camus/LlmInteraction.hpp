// =================================================================
// include/Camus/LlmInteraction.hpp
// =================================================================
// Defines the interface for interacting with the local LLM via llama.cpp.

#pragma once

#include <string>
#include <vector>

// Forward declare llama.cpp structs to keep the header clean
struct llama_model;
struct llama_context;

namespace Camus {

class LlmInteraction {
public:
    /**
     * @brief Constructor loads the model and initializes the context.
     * @param model_path Full path to the GGUF model file.
     */
    explicit LlmInteraction(const std::string& model_path);
    ~LlmInteraction();

    // Disable copy and move semantics for this class as it manages raw pointers.
    LlmInteraction(const LlmInteraction&) = delete;
    LlmInteraction& operator=(const LlmInteraction&) = delete;
    LlmInteraction(LlmInteraction&&) = delete;
    LlmInteraction& operator=(LlmInteraction&&) = delete;

    /**
     * @brief Sends a prompt to the LLM and gets a response.
     * @param prompt The fully-formed prompt to send to the model.
     * @return The text generated by the model.
     */
    std::string getCompletion(const std::string& prompt);

private:
    llama_model* m_model = nullptr;
    llama_context* m_context = nullptr;
};

} // namespace Camus
