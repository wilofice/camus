// =================================================================
// include/Camus/LlamaCppInteraction.hpp
// =================================================================
// Concrete implementation of LlmInteraction using llama.cpp.

#pragma once

#include "Camus/LlmInteraction.hpp"
#include <string>

// Forward declare llama.cpp structs to keep the header clean
struct llama_model;
struct llama_context;

namespace Camus {

class LlamaCppInteraction : public LlmInteraction {
public:
    /**
     * @brief Constructor loads the model and initializes the context.
     * @param model_path Full path to the GGUF model file.
     */
    explicit LlamaCppInteraction(const std::string& model_path);
    ~LlamaCppInteraction() override;

    // Disable copy and move semantics for this class as it manages raw pointers.
    LlamaCppInteraction(const LlamaCppInteraction&) = delete;
    LlamaCppInteraction& operator=(const LlamaCppInteraction&) = delete;
    LlamaCppInteraction(LlamaCppInteraction&&) = delete;
    LlamaCppInteraction& operator=(LlamaCppInteraction&&) = delete;

    /**
     * @brief Sends a prompt to the LLM and gets a response.
     * @param prompt The fully-formed prompt to send to the model.
     * @return The text generated by the model.
     */
    std::string getCompletion(const std::string& prompt) override;

private:
    llama_model* m_model = nullptr;
    llama_context* m_context = nullptr;
};

} // namespace Camus